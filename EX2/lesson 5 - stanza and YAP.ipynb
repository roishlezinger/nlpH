{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook enables comparing stanza and YAP for Hebrew text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import stanza\n",
    "import requests\n",
    "import json\n",
    "from time import sleep\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Processor:\n",
    "    def __init__(self):\n",
    "        self.heb_nlp = stanza.Pipeline(lang='he', processors='tokenize,mwt,pos,lemma,depparse')\n",
    "        #replace MY_TOKEN with the token you got from the langndata website\n",
    "        self.yap_token=\"MY_TOKEN\"\n",
    "    \n",
    "    def print_stanza_analysis(self, text):\n",
    "        text += \" XX\"\n",
    "        doc=self.heb_nlp(text)\n",
    "        lst=[]\n",
    "        for sen in doc.sentences:\n",
    "            for token in sen.tokens:\n",
    "                for word in token.words:\n",
    "                    features=[(word.text,\n",
    "                               word.lemma,\n",
    "                               word.upos,\n",
    "                               word.xpos,\n",
    "                               word.head,\n",
    "                               word.deprel,\n",
    "                               word.feats)]\n",
    "\n",
    "                    df=pd.DataFrame(features, columns=[\"text\", \"lemma\", \"upos\", \"xpos\", \"head\", \"deprel\",\"feats\"])\n",
    "                    lst.append(df)\n",
    "        tot_df=pd.concat(lst, ignore_index=True)\n",
    "        tot_df=tot_df.shift(1).iloc[1:]\n",
    "        tot_df[\"head\"]=tot_df[\"head\"].astype(int)\n",
    "        print(tot_df.head(50))\n",
    "        \n",
    "    def print_yap_analysis(self, text):\n",
    "        text= text.replace(r'\"', r'\\\"')\n",
    "        url = f'https://www.langndata.com/api/heb_parser?token={self.yap_token}'\n",
    "        _json='{\"data\":\"'+text.strip()+'\"}'\n",
    "#         print(url)\n",
    "#         print(_json)\n",
    "        headers = {'content-type': 'application/json'}\n",
    "        sleep(0.5)\n",
    "        r = requests.post(url,  data=_json.encode('utf-8'), headers={'Content-type': 'application/json; charset=utf-8'})\n",
    "        json_obj=r.json()\n",
    "        print\n",
    "        md_lattice=json_obj[\"md_lattice\"]\n",
    "        res_df=pd.io.json.json_normalize([md_lattice[i] for i in md_lattice.keys()])\n",
    "        print(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-07 11:13:37 INFO: Loading these models for language: he (Hebrew):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | htb     |\n",
      "| mwt       | htb     |\n",
      "| pos       | htb     |\n",
      "| lemma     | htb     |\n",
      "| depparse  | htb     |\n",
      "=======================\n",
      "\n",
      "2020-05-07 11:13:37 INFO: Use device: cpu\n",
      "2020-05-07 11:13:37 INFO: Loading: tokenize\n",
      "2020-05-07 11:13:37 INFO: Loading: mwt\n",
      "2020-05-07 11:13:37 INFO: Loading: pos\n",
      "2020-05-07 11:13:40 INFO: Loading: lemma\n",
      "2020-05-07 11:13:40 INFO: Loading: depparse\n",
      "2020-05-07 11:13:42 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     text  lemma   upos   xpos  head           deprel  \\\n",
      "1     הוא    הוא   PRON   PRON     2            nsubj   \n",
      "2    הפיל   הפיל   VERB   VERB     0             root   \n",
      "3       ה      ה    DET    DET     4          det:def   \n",
      "4    גדול   גדול    ADJ    ADJ     2        parataxis   \n",
      "5   ביותר  ביותר    ADV    ADV     4           advmod   \n",
      "6       ב      ב    ADP    ADP     7             case   \n",
      "7      גן     גן   NOUN   NOUN     2              obl   \n",
      "8       ה      ה    DET    DET     9          det:def   \n",
      "9    חיות    חיה   NOUN   NOUN     7  compound:smixut   \n",
      "10      .      .  PUNCT  PUNCT     2            punct   \n",
      "\n",
      "                                                feats  \n",
      "1       Gender=Masc|Number=Sing|Person=3|PronType=Prs  \n",
      "2   Gender=Masc|HebBinyan=HIFIL|Number=Sing|Person...  \n",
      "3                                        PronType=Art  \n",
      "4                             Gender=Masc|Number=Sing  \n",
      "5                                                None  \n",
      "6                                                None  \n",
      "7               Definite=Cons|Gender=Masc|Number=Sing  \n",
      "8                                        PronType=Art  \n",
      "9                              Gender=Fem|Number=Plur  \n",
      "10                                               None  \n"
     ]
    }
   ],
   "source": [
    "text=\"\"\"\n",
    "הוא הפיל הגדול ביותר בגן החיות.\n",
    "\"\"\"\n",
    "processor=Processor()\n",
    "processor.print_stanza_analysis(text)\n",
    "#processor.print_yap_analysis(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-07 11:17:19 INFO: Loading these models for language: he (Hebrew):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | htb     |\n",
      "| mwt       | htb     |\n",
      "| pos       | htb     |\n",
      "| lemma     | htb     |\n",
      "| depparse  | htb     |\n",
      "=======================\n",
      "\n",
      "2020-05-07 11:17:19 INFO: Use device: cpu\n",
      "2020-05-07 11:17:19 INFO: Loading: tokenize\n",
      "2020-05-07 11:17:19 INFO: Loading: mwt\n",
      "2020-05-07 11:17:19 INFO: Loading: pos\n",
      "2020-05-07 11:17:21 INFO: Loading: lemma\n",
      "2020-05-07 11:17:21 INFO: Loading: depparse\n",
      "2020-05-07 11:17:23 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.langndata.com/api/heb_parser?token=7af849ffe433366fa59173445cee7ac7\n",
      "{\"data\":\"הוא הפיל הגדול ביותר בגן החיות.\"}\n",
      "    empty gen  lemma num num_2 num_last num_s_p per          pos        pos_2  \\\n",
      "0      -1   M    הוא   0     1        1       S   3          PRP          PRP   \n",
      "1      -1  -1      ה   1     2        2      -1  -1          DEF          DEF   \n",
      "2      -1   M    פיל   2     3        2       S  -1           NN           NN   \n",
      "3      -1  -1      ה   3     4        3      -1  -1          DEF          DEF   \n",
      "4      -1   M   גדול   4     5        3       S  -1           JJ           JJ   \n",
      "5      -1  -1  ביותר   5     6        4      -1  -1           RB           RB   \n",
      "6      -1  -1      ב   6     7        5      -1  -1  PREPOSITION  PREPOSITION   \n",
      "7      -1  -1      ה   7     8        5      -1  -1          DEF          DEF   \n",
      "8      -1   M     גן   8     9        5       S  -1           NN           NN   \n",
      "9      -1  -1      ה   9    10        6      -1  -1          DEF          DEF   \n",
      "10     -1   F     חי  10    11        6       P  -1           JJ           JJ   \n",
      "11     -1  -1      _  11    12        7      -1  -1        yyDOT        yyDOT   \n",
      "\n",
      "    tense   word  \n",
      "0      -1    הוא  \n",
      "1      -1      ה  \n",
      "2      -1    פיל  \n",
      "3      -1      ה  \n",
      "4      -1   גדול  \n",
      "5      -1  ביותר  \n",
      "6      -1      ב  \n",
      "7      -1      ה  \n",
      "8      -1     גן  \n",
      "9      -1      ה  \n",
      "10     -1   חיות  \n",
      "11     -1      .  \n"
     ]
    }
   ],
   "source": [
    "text=\"\"\"\n",
    "הוא הפיל הגדול ביותר בגן החיות.\n",
    "\"\"\"\n",
    "processor=Processor()\n",
    "#processor.print_stanza_analysis(text)\n",
    "processor.print_yap_analysis(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hebnlp",
   "language": "python",
   "name": "hebnlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
